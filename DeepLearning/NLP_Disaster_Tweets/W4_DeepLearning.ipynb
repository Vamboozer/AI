{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Disaster Tweets RNN Model by Marshall Folkman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description\n",
    "\n",
    "The problem this Kaggle competition poses is the automatic identification and classification of real-time disaster-related tweets from a sea of everyday communications. With the proliferation of social media and the immediacy of information transmission it offers, agencies such as disaster relief organizations and news agencies aim to leverage this platform for effective disaster management. However, the challenge lies in distinguishing tweets that are truly about real-world disasters from those that use disaster-related language metaphorically. Participants are tasked with building a machine learning model that can discern between these two categories, providing a meaningful way to triage emergency-related communication on Twitter.\n",
    "\n",
    "The data provided for this task is a collection of 10,000 tweets, split into a training set and a test set, both encompassing the tweet text, a keyword from the tweet (which may be absent), and the tweet's location (which may also be absent). These features form the basis for the machine learning model. The training data additionally includes a target variable, which denotes whether the tweet is about a real disaster (represented by '1') or not (represented by '0'). The ultimate objective of the competition is to make accurate predictions on the test data based on the patterns learned from the training data, thereby determining if a given tweet refers to a genuine disaster or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.17 (main, Jul  5 2023, 20:47:11) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "# Requires: pip install pandas matplotlib seaborn tensorflow scikit-learn nltk gensim\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sys\n",
    "print(sys.version)\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#from nltk.stem.porter import PorterStemmer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.layers import GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the google word2vec model\n",
    "filename = 'D:\\OneDrive\\_CU-MSEE\\AI\\DTSA5511_DeepLearning\\Week4\\GoogleNews-vectors-negative300.bin'  # path to the Word2Vec file\n",
    "word2vec_model = KeyedVectors.load_word2vec_format(filename, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id keyword location                                               text  \\\n",
      "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
      "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
      "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
      "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
      "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
      "\n",
      "   target  \n",
      "0       1  \n",
      "1       1  \n",
      "2       1  \n",
      "3       1  \n",
      "4       1  \n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('D:/OneDrive/_CU-MSEE/AI/DTSA5511_DeepLearning/Week4/nlp-getting-started/train.csv')\n",
    "test_data = pd.read_csv('D:/OneDrive/_CU-MSEE/AI/DTSA5511_DeepLearning/Week4/nlp-getting-started/test.csv')\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Show a summary of the DataFrame\n",
    "print(train_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id      target\n",
      "count   7613.000000  7613.00000\n",
      "mean    5441.934848     0.42966\n",
      "std     3137.116090     0.49506\n",
      "min        1.000000     0.00000\n",
      "25%     2734.000000     0.00000\n",
      "50%     5408.000000     0.00000\n",
      "75%     8146.000000     1.00000\n",
      "max    10873.000000     1.00000\n"
     ]
    }
   ],
   "source": [
    "# Show statistics of the numerical columns\n",
    "print(train_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 7613 unique values\n",
      "keyword: 221 unique values\n",
      "location: 3341 unique values\n",
      "text: 7503 unique values\n",
      "target: 2 unique values\n"
     ]
    }
   ],
   "source": [
    "# Count of unique values in each column\n",
    "for column in train_data.columns:\n",
    "    print(f\"{column}: {train_data[column].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id             0\n",
      "keyword       61\n",
      "location    2533\n",
      "text           0\n",
      "target         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Show any missing values\n",
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    4342\n",
      "1    3271\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count the number of each target class\n",
    "target_counts = train_data['target'].value_counts()\n",
    "print(target_counts)\n",
    "\n",
    "# Visualize the class distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=target_counts.index, y=target_counts.values, alpha=0.8)\n",
    "plt.title('Distribution of Target variable')\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('Target', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This 'target' imbalance is not extreme so it's less likely that bias will be an issue, but its off enough to keep it in mind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this juncture, it is pretty obvious that I will need to use a RNN architecture such as LSTM or GRU. Lets gather more data to help us decide which would be a better use model for this dataset. Then, we'll start preparing the data specifically for that model. Both LSTM and GRU are designed to handle long sequences, but if most of the sentences are short, then the simpler GRU might perform just as well and train faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analyze sentence length\n",
    "train_data['text_length'] = train_data['text'].apply(lambda x: len(x.split()))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(train_data['text_length'], bins=30)\n",
    "plt.title('Sentence Length Distribution')\n",
    "plt.xlabel('Number of Words')\n",
    "plt.ylabel('Number of Tweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normal-like distribution of the sentence lengths suggests there isn't an extreme bias towards very short or very long sentences. This is important because we need to get an idea of how to set our maximum sequence length and understand the computational complexity of training this model. Considering the observed range of tweet lengths and the subjects studied, I've determined that starting with an LSTM model would be beneficial. LSTM, or Long Short-Term Memory networks, are a form of RNN that excel at learning from data that exhibit long-term dependencies, a characteristic common in text data. Furthermore, LSTMs are known to handle the vanishing gradient problem more efficiently than vanilla RNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets get a better idea of how this data should be best cleaned in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words: [('the', 2575), ('a', 1845), ('to', 1805), ('in', 1757), ('of', 1722), ('and', 1302), ('I', 1197), ('for', 820), ('is', 814), ('on', 773)]\n",
      "Least common words: [('http://t.co/YmY4rSkQ3d', 1), ('http://t.co/STfMbbZFB5', 1), ('http://t.co/nF4IculOje', 1), ('flip', 1), ('http://t.co/rqKK15uhEY', 1), ('symptoms...', 1), ('developing', 1), ('Forney', 1), ('http://t.co/5ueCmcv2Pk', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each word\n",
    "word_counts = Counter()\n",
    "train_data['text'].str.split().apply(word_counts.update)\n",
    "\n",
    "# Most common words\n",
    "print(\"Most common words:\", word_counts.most_common(10))\n",
    "\n",
    "# Least common words\n",
    "print(\"Least common words:\", word_counts.most_common()[:-10:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words before cleaning: 31924\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'clean_text' is your column with the cleaned tweet text\n",
    "# First, we split each tweet into words, creating a list of lists\n",
    "split_tweets = train_data['text'].str.split()\n",
    "\n",
    "# Then, we flatten the list of lists into a single list containing all words\n",
    "all_words = [word for tweet in split_tweets for word in tweet]\n",
    "\n",
    "# Now we use Counter to count unique words\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "# The total number of unique words is the length of this Counter object\n",
    "num_unique_words_before_cleaning = len(word_counts)\n",
    "\n",
    "print(f\"Number of unique words before cleaning: {num_unique_words_before_cleaning}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can see that we will need to remove our 'outliers' during our cleaning process. Specifically I will need to remove things like 'Stopwords', punctuation, numbers, and non-alphabetic characters as these are very often seen throughout the dataset and don't add meanful value to our model. Then, we will need to also remove the other extreme, words seen only once or a few times as this data doesn't correlate to anything else or very little to other data and therefore doesn't add value. Enough chat, lets get cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words: [('like', 345), ('amp', 298), ('fire', 250), ('get', 229), ('new', 224), ('via', 220), ('people', 195), ('one', 193), ('news', 192), ('dont', 191)]\n",
      "Least common words: [('symptoms', 1), ('developing', 1), ('forney', 1), ('9km', 1), ('bathandnortheastsomerset', 1), ('overtaking', 1), ('fatherofthree', 1), ('tnwx', 1), ('explosivespacked', 1)]\n",
      "target: 2 unique values\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove urls\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove user @ references and '#' from text\n",
    "    text = re.sub(r'\\@\\w+|\\#','', text)\n",
    "    \n",
    "    # Remove punctuations\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = \" \".join([word for word in str(text).split() if word not in stop_words])\n",
    "    \n",
    "    # Remove words less than 2 characters\n",
    "    text = \" \".join([word for word in text.split() if len(word) > 2])\n",
    "\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to both test and training datasets\n",
    "train_data['text'] = train_data['text'].apply(lambda x: clean_text(x))\n",
    "test_data['text'] = test_data['text'].apply(lambda x: clean_text(x))\n",
    "\n",
    "# Count occurrences of each word\n",
    "word_counts = Counter()\n",
    "train_data['text'].str.split().apply(word_counts.update)\n",
    "\n",
    "# Most common words\n",
    "print(\"Most common words:\", word_counts.most_common(10))\n",
    "\n",
    "# Least common words\n",
    "print(\"Least common words:\", word_counts.most_common()[:-10:-1])\n",
    "\n",
    "# Print number of unique words in text field\n",
    "print(f\"{column}: {train_data[column].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words after cleaning: 15342\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'clean_text' is your column with the cleaned tweet text\n",
    "# First, we split each tweet into words, creating a list of lists\n",
    "split_tweets = train_data['text'].str.split()\n",
    "\n",
    "# Then, we flatten the list of lists into a single list containing all words\n",
    "all_words = [word for tweet in split_tweets for word in tweet]\n",
    "\n",
    "# Now we use Counter to count unique words\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "# The total number of unique words is the length of this Counter object\n",
    "num_unique_words_after_cleaning = len(word_counts)\n",
    "\n",
    "print(f\"Number of unique words after cleaning: {num_unique_words_after_cleaning}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data seems to be well cleaned. Now let's move onto the next steps, which are tokenizing and padding the text data for a LSTM model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define maximum number of words to consider as features\n",
    "max_features = num_unique_words_after_cleaning\n",
    "\n",
    "# Load the data\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "\n",
    "# Fit the tokenizer on the text\n",
    "tokenizer.fit_on_texts(list(train_data['text']))\n",
    "\n",
    "# Transform the text to sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(train_data['text'])\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut texts after this number of words \n",
    "# (among top max_features most common words)\n",
    "maxlen = 30\n",
    "\n",
    "# Pad the sequences\n",
    "X_train = pad_sequences(train_sequences, maxlen=maxlen)\n",
    "X_test = pad_sequences(test_sequences, maxlen=maxlen)\n",
    "\n",
    "# Define the labels\n",
    "y_train = train_data['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 30, 128)           1963776   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                49408     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2013249 (7.68 MB)\n",
      "Trainable params: 2013249 (7.68 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "191/191 [==============================] - 15s 62ms/step - loss: 0.5411 - accuracy: 0.7292 - val_loss: 0.4674 - val_accuracy: 0.7840\n",
      "Epoch 2/5\n",
      "191/191 [==============================] - 10s 53ms/step - loss: 0.2888 - accuracy: 0.8872 - val_loss: 0.4853 - val_accuracy: 0.7899\n",
      "Epoch 3/5\n",
      "191/191 [==============================] - 10s 50ms/step - loss: 0.1696 - accuracy: 0.9381 - val_loss: 0.5917 - val_accuracy: 0.7354\n",
      "Epoch 4/5\n",
      "191/191 [==============================] - 9s 49ms/step - loss: 0.1132 - accuracy: 0.9621 - val_loss: 0.6277 - val_accuracy: 0.7669\n",
      "Epoch 5/5\n",
      "191/191 [==============================] - 9s 48ms/step - loss: 0.0903 - accuracy: 0.9691 - val_loss: 0.7007 - val_accuracy: 0.7439\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, input_length=maxlen))\n",
    "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size=32, \n",
    "                    epochs=5, \n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at these results, the training accuracy is increasing after each epoch, but the validation accuracy is decreasing. This discrepancy suggests that the model might be starting to memorize the training data (overfitting) rather than learning to generalize from it. Also, the validation loss is increasing after each epoch, which is another sign of overfitting. While the model is becoming more confident in its predictions on the training data (lower loss), it's becoming less confident in its predictions on the validation data (higher loss)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 2 - Tune the learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think the most intuitive hyperparameter to tune first is the learning rate. I will use a technique called \"Learning Rate Scheduling\" to adjust the learning rate while training. Specifically, I'll use a technique called \"ReduceLROnPlateau\". This technique reduces the learning rate once the model's performance stops improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "191/191 [==============================] - 13s 54ms/step - loss: 0.5458 - accuracy: 0.7207 - val_loss: 0.4569 - val_accuracy: 0.7899 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "191/191 [==============================] - 9s 48ms/step - loss: 0.2929 - accuracy: 0.8826 - val_loss: 0.4731 - val_accuracy: 0.7800 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "191/191 [==============================] - 9s 47ms/step - loss: 0.1707 - accuracy: 0.9396 - val_loss: 0.5508 - val_accuracy: 0.7708 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "191/191 [==============================] - 11s 58ms/step - loss: 0.1156 - accuracy: 0.9604 - val_loss: 0.6246 - val_accuracy: 0.7479 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "191/191 [==============================] - 10s 52ms/step - loss: 0.0876 - accuracy: 0.9696 - val_loss: 0.7071 - val_accuracy: 0.7446 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, input_length=maxlen))\n",
    "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Create the learning rate reduction strategy\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size=32, \n",
    "                    epochs=5, \n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't do much to reduce overfitting. Lets get more aggressive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 3 - More dropout, add regularization, increase validation split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code introduces a larger amount of dropout (0.5 vs 0.2) and regularization to prevent overfitting. It also increases the validation split from 0.2 to 0.3, so that more data is used to evaluate the model during training, which might help to improve the model's robustness on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "191/191 [==============================] - 16s 65ms/step - loss: 0.9873 - accuracy: 0.6138 - val_loss: 0.6160 - val_accuracy: 0.7282 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "191/191 [==============================] - 13s 66ms/step - loss: 0.4666 - accuracy: 0.8172 - val_loss: 0.5011 - val_accuracy: 0.7800 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "191/191 [==============================] - 12s 65ms/step - loss: 0.3583 - accuracy: 0.8703 - val_loss: 0.4978 - val_accuracy: 0.7859 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "191/191 [==============================] - 12s 61ms/step - loss: 0.2922 - accuracy: 0.8969 - val_loss: 0.5077 - val_accuracy: 0.7708 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "191/191 [==============================] - 10s 53ms/step - loss: 0.2459 - accuracy: 0.9187 - val_loss: 0.5396 - val_accuracy: 0.7656 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Layers:\n",
    "model.add(Embedding(max_features, 128, input_length=maxlen))    # Embedding layer\n",
    "model.add(Dropout(0.5))                                         # Dropout layer\n",
    "model.add(LSTM(64, dropout=0.5, \n",
    "               recurrent_dropout=0.5, \n",
    "               kernel_regularizer=regularizers.l2(0.01)))       # LSTM layer with dropout and recurrent dropout and L2 regularization\n",
    "model.add(Dropout(0.5))                                         # Dropout layer\n",
    "model.add(Dense(1, activation='sigmoid'))                       # Dense layer\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Create the learning rate reduction strategy\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size=32, \n",
    "                    epochs=5, \n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This helped a little, but not near enough to eliminate the overfitting. Notice that we are still seeing the training accuracy significantly better than the validation accuracy. Also, validation loss is still increasing after the second epoch, which is a sign that the model is becoming more confident in its incorrect predictions over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 4 - Decrease Model Complexity and implement early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try reducing the model complexity by decreasing the number of neurons in the LSTM layer and reduce the dimensionality of the Embedding layer. We will also implement early stopping to prevent overfitting even more when it notices that the validation loss stops decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "191/191 [==============================] - 12s 41ms/step - loss: 0.9022 - accuracy: 0.5834 - val_loss: 0.6807 - val_accuracy: 0.5653 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "191/191 [==============================] - 7s 36ms/step - loss: 0.5350 - accuracy: 0.7798 - val_loss: 0.5208 - val_accuracy: 0.7768 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "191/191 [==============================] - 7s 34ms/step - loss: 0.3854 - accuracy: 0.8598 - val_loss: 0.4822 - val_accuracy: 0.7899 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "191/191 [==============================] - 7s 34ms/step - loss: 0.3249 - accuracy: 0.8857 - val_loss: 0.5054 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "191/191 [==============================] - 7s 35ms/step - loss: 0.2802 - accuracy: 0.9074 - val_loss: 0.5223 - val_accuracy: 0.7669 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "191/191 [==============================] - 7s 35ms/step - loss: 0.2396 - accuracy: 0.9209 - val_loss: 0.5120 - val_accuracy: 0.7689 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Layers:\n",
    "model.add(Embedding(max_features, 64, input_length=maxlen))    # Embedding layer with reduced dimensionality\n",
    "model.add(Dropout(0.5))                                        # Dropout layer\n",
    "model.add(LSTM(32, dropout=0.5,                                # LSTM layer with fewer neurons\n",
    "               recurrent_dropout=0.5, \n",
    "               kernel_regularizer=regularizers.l2(0.01)))       \n",
    "model.add(Dropout(0.5))                                        # Dropout layer\n",
    "model.add(Dense(1, activation='sigmoid'))                      # Dense layer\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Create the learning rate reduction and early stopping strategies\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size=32, \n",
    "                    epochs=20,    # Increase epochs as EarlyStopping will stop training when necessary\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[reduce_lr, early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better, but we're still way out of the park."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 5 - Use pre-trained word embeddings (Word2Vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-trained embeddings like Google's Word2Vec may improve model performance by leveraging pre-existing knowledge about word relationships. This should help us a lot since we are working with a small training dataset for the complexity of the problem at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "191/191 [==============================] - 10s 33ms/step - loss: 1.0353 - accuracy: 0.6883 - val_loss: 0.5689 - val_accuracy: 0.8017 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "191/191 [==============================] - 7s 34ms/step - loss: 0.5807 - accuracy: 0.7599 - val_loss: 0.5120 - val_accuracy: 0.8050 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "191/191 [==============================] - 6s 33ms/step - loss: 0.5561 - accuracy: 0.7647 - val_loss: 0.4922 - val_accuracy: 0.8096 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "191/191 [==============================] - 6s 34ms/step - loss: 0.5471 - accuracy: 0.7631 - val_loss: 0.4798 - val_accuracy: 0.8116 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "191/191 [==============================] - 6s 33ms/step - loss: 0.5508 - accuracy: 0.7594 - val_loss: 0.4791 - val_accuracy: 0.8063 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "191/191 [==============================] - 7s 34ms/step - loss: 0.5391 - accuracy: 0.7647 - val_loss: 0.4812 - val_accuracy: 0.8056 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "191/191 [==============================] - 6s 34ms/step - loss: 0.5458 - accuracy: 0.7575 - val_loss: 0.4802 - val_accuracy: 0.8188 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "191/191 [==============================] - 7s 35ms/step - loss: 0.5464 - accuracy: 0.7619 - val_loss: 0.4807 - val_accuracy: 0.7991 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((max_features, 300))  # Word2Vec has 300 dimensions\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= max_features:\n",
    "        continue\n",
    "    if word in word2vec_model:  # changed variable name here\n",
    "        embedding_matrix[i] = word2vec_model[word]  # and here\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()  # This is your Sequential model\n",
    "\n",
    "# Layers:\n",
    "model.add(Embedding(max_features, \n",
    "                    300,  # dimensionality of the Word2Vec embeddings\n",
    "                    weights=[embedding_matrix], \n",
    "                    input_length=maxlen,\n",
    "                    trainable=False)) # set trainable=False to prevent the weights from being updated during training\n",
    "model.add(Dropout(0.5))                                        # Dropout layer\n",
    "model.add(LSTM(32, dropout=0.5,                                # LSTM layer with fewer neurons\n",
    "               recurrent_dropout=0.5, \n",
    "               kernel_regularizer=regularizers.l2(0.01)))       \n",
    "model.add(Dropout(0.5))                                        # Dropout layer\n",
    "model.add(Dense(1, activation='sigmoid'))                      # Dense layer\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Create the learning rate reduction and early stopping strategies\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size=32, \n",
    "                    epochs=20,    # Increase epochs as EarlyStopping will stop training when necessary\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[reduce_lr, early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are better than before, showing that using pre-trained Word2Vec embeddings has improved my model's performance. However, there's still a small gap between training and validation accuracy, which indicates we still have overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 6 - More aggressive settings tuning to eliminate overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's adjust the dropout rates, the learning rate, the batch size, and the number of neurons in the LSTM layer more aggressively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "96/96 [==============================] - 11s 76ms/step - loss: 2.2770 - accuracy: 0.5972 - val_loss: 1.3973 - val_accuracy: 0.6993 - lr: 5.0000e-04\n",
      "Epoch 2/20\n",
      "96/96 [==============================] - 7s 68ms/step - loss: 1.0517 - accuracy: 0.7209 - val_loss: 0.7651 - val_accuracy: 0.7715 - lr: 5.0000e-04\n",
      "Epoch 3/20\n",
      "96/96 [==============================] - 7s 72ms/step - loss: 0.7229 - accuracy: 0.7407 - val_loss: 0.5969 - val_accuracy: 0.7945 - lr: 5.0000e-04\n",
      "Epoch 4/20\n",
      "96/96 [==============================] - 7s 71ms/step - loss: 0.6326 - accuracy: 0.7512 - val_loss: 0.5435 - val_accuracy: 0.8030 - lr: 5.0000e-04\n",
      "Epoch 5/20\n",
      "96/96 [==============================] - 7s 70ms/step - loss: 0.6105 - accuracy: 0.7450 - val_loss: 0.5236 - val_accuracy: 0.8102 - lr: 5.0000e-04\n",
      "Epoch 6/20\n",
      "96/96 [==============================] - 7s 71ms/step - loss: 0.5862 - accuracy: 0.7442 - val_loss: 0.5104 - val_accuracy: 0.8076 - lr: 5.0000e-04\n",
      "Epoch 7/20\n",
      "96/96 [==============================] - 7s 71ms/step - loss: 0.5691 - accuracy: 0.7493 - val_loss: 0.5074 - val_accuracy: 0.8070 - lr: 5.0000e-04\n",
      "Epoch 8/20\n",
      "96/96 [==============================] - 7s 71ms/step - loss: 0.5625 - accuracy: 0.7473 - val_loss: 0.4959 - val_accuracy: 0.8050 - lr: 5.0000e-04\n",
      "Epoch 9/20\n",
      "96/96 [==============================] - 7s 74ms/step - loss: 0.5554 - accuracy: 0.7522 - val_loss: 0.4888 - val_accuracy: 0.8070 - lr: 5.0000e-04\n",
      "Epoch 10/20\n",
      "96/96 [==============================] - 7s 74ms/step - loss: 0.5546 - accuracy: 0.7452 - val_loss: 0.4880 - val_accuracy: 0.8096 - lr: 5.0000e-04\n",
      "Epoch 11/20\n",
      "96/96 [==============================] - 7s 75ms/step - loss: 0.5541 - accuracy: 0.7491 - val_loss: 0.5023 - val_accuracy: 0.7932 - lr: 5.0000e-04\n",
      "Epoch 12/20\n",
      "96/96 [==============================] - 7s 71ms/step - loss: 0.5575 - accuracy: 0.7466 - val_loss: 0.4940 - val_accuracy: 0.8043 - lr: 5.0000e-04\n",
      "Epoch 13/20\n",
      "96/96 [==============================] - 7s 72ms/step - loss: 0.5526 - accuracy: 0.7445 - val_loss: 0.4859 - val_accuracy: 0.8076 - lr: 5.0000e-04\n",
      "Epoch 14/20\n",
      "96/96 [==============================] - 7s 74ms/step - loss: 0.5602 - accuracy: 0.7463 - val_loss: 0.4843 - val_accuracy: 0.8037 - lr: 5.0000e-04\n",
      "Epoch 15/20\n",
      "96/96 [==============================] - 7s 75ms/step - loss: 0.5547 - accuracy: 0.7452 - val_loss: 0.4859 - val_accuracy: 0.8011 - lr: 5.0000e-04\n",
      "Epoch 16/20\n",
      "96/96 [==============================] - 7s 75ms/step - loss: 0.5557 - accuracy: 0.7386 - val_loss: 0.4883 - val_accuracy: 0.8050 - lr: 5.0000e-04\n",
      "Epoch 17/20\n",
      "96/96 [==============================] - 7s 73ms/step - loss: 0.5503 - accuracy: 0.7460 - val_loss: 0.4889 - val_accuracy: 0.8017 - lr: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((max_features, 300))  # Word2Vec has 300 dimensions\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= max_features:\n",
    "        continue\n",
    "    if word in word2vec_model:  \n",
    "        embedding_matrix[i] = word2vec_model[word] \n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Layers:\n",
    "model.add(Embedding(max_features, \n",
    "                    300,  # dimensionality of the Word2Vec embeddings\n",
    "                    weights=[embedding_matrix], \n",
    "                    input_length=maxlen,\n",
    "                    trainable=False)) # set trainable=False to prevent the weights from being updated during training\n",
    "model.add(Dropout(0.6))  # Increased dropout rate\n",
    "model.add(LSTM(64, dropout=0.6,  # Increased LSTM neurons and dropout rate\n",
    "               recurrent_dropout=0.6, \n",
    "               kernel_regularizer=regularizers.l2(0.01)))       \n",
    "model.add(Dropout(0.6))  # Increased dropout rate\n",
    "model.add(Dense(1, activation='sigmoid'))                     \n",
    "\n",
    "# Compile the model\n",
    "from keras.optimizers import Adam\n",
    "opt = Adam(learning_rate=0.0005)  # Reduced learning rate\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=opt,  # Using the new learning rate\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Create the learning rate reduction and early stopping strategies\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size=64,  # Increased batch size\n",
    "                    epochs=20,    # Increase epochs as EarlyStopping will stop training when necessary\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[reduce_lr, early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 7 - Switch from LSTM to GRU layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "191/191 [==============================] - 11s 36ms/step - loss: 1.0629 - accuracy: 0.6603 - val_loss: 0.6039 - val_accuracy: 0.8096 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "191/191 [==============================] - 5s 29ms/step - loss: 0.6172 - accuracy: 0.7481 - val_loss: 0.5458 - val_accuracy: 0.7768 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "191/191 [==============================] - 5s 29ms/step - loss: 0.5717 - accuracy: 0.7522 - val_loss: 0.5056 - val_accuracy: 0.8017 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 0.5577 - accuracy: 0.7581 - val_loss: 0.4963 - val_accuracy: 0.8083 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 0.5517 - accuracy: 0.7621 - val_loss: 0.4893 - val_accuracy: 0.8116 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "191/191 [==============================] - 5s 29ms/step - loss: 0.5524 - accuracy: 0.7542 - val_loss: 0.4869 - val_accuracy: 0.8070 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 0.5467 - accuracy: 0.7570 - val_loss: 0.4787 - val_accuracy: 0.7991 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 0.5477 - accuracy: 0.7591 - val_loss: 0.4919 - val_accuracy: 0.8017 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 0.5464 - accuracy: 0.7581 - val_loss: 0.4962 - val_accuracy: 0.8017 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 0.5385 - accuracy: 0.7637 - val_loss: 0.4815 - val_accuracy: 0.8089 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((max_features, 300))  # Word2Vec has 300 dimensions\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= max_features:\n",
    "        continue\n",
    "    if word in word2vec_model:  # changed variable name here\n",
    "        embedding_matrix[i] = word2vec_model[word]  # and here\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()  # This is your Sequential model\n",
    "\n",
    "# Layers:\n",
    "model.add(Embedding(max_features, \n",
    "                    300,  # dimensionality of the Word2Vec embeddings\n",
    "                    weights=[embedding_matrix], \n",
    "                    input_length=maxlen,\n",
    "                    trainable=False)) # set trainable=False to prevent the weights from being updated during training\n",
    "model.add(Dropout(0.5))                                        # Dropout layer\n",
    "model.add(GRU(32, dropout=0.5,                                 # GRU layer with 32 neurons\n",
    "              recurrent_dropout=0.5, \n",
    "              kernel_regularizer=regularizers.l2(0.01)))       # Regularization\n",
    "model.add(Dropout(0.5))                                        # Dropout layer\n",
    "model.add(Dense(1, activation='sigmoid'))                      # Dense layer\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Create the learning rate reduction and early stopping strategies\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size=32, \n",
    "                    epochs=20,    # Increase epochs as EarlyStopping will stop training when necessary\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[reduce_lr, early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems the GRU model performed better than the LSTM model in terms of training speed and validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems we've picked up all the low hanging fruit. We know there is a lot more we could do to improve the model, but based on how slowing we're able to improve the model over recent iterations we will call this good enough and move on to testing against the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create final submission to be graded by Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 2s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predicting with the model\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Convert probabilities into binary outputs\n",
    "y_test_pred = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "# Create a submission DataFrame with 'id' and 'target'\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_data['id'],\n",
    "    'target': y_test_pred.squeeze(),  # .squeeze() is used to get the correct dimension\n",
    "})\n",
    "\n",
    "# Write the DataFrame to a csv file\n",
    "submission.to_csv('submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Leaderboard](Leaderboard.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My model to classify text-based data using natural language processing techniques. We implemented various neural network architectures such as LSTM and GRU, experimented with different hyperparameters and used Word2Vec for word embeddings to enhance the model's performance.\n",
    "\n",
    "Despite some initial challenges, the final model achieved an accuracy of approximately 0.78823 on the Kaggle competition test set. This indicates that our model is capable of reasonably accurate predictions. While the accuracy achieved is satisfactory, there is potential for further improvements. For future work, we could experiment with other model architectures, advanced NLP techniques, or fine-tuning of Word2Vec embeddings to enhance the model's predictive performance. Moreover, we could also investigate the use of ensemble techniques, which often prove beneficial in boosting the performance of individual models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepW4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
